[{"path":"https://cmatkhan.github.io/BSA/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to BSA","title":"Contributing to BSA","text":"outlines propose change BSA. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"https://cmatkhan.github.io/BSA/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to BSA","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://cmatkhan.github.io/BSA/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to BSA","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"https://cmatkhan.github.io/BSA/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to BSA","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"cmatKhan/BSA\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://cmatkhan.github.io/BSA/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to BSA","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://cmatkhan.github.io/BSA/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to BSA","text":"Please note BSA project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://cmatkhan.github.io/BSA/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 chase mateusiak Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://cmatkhan.github.io/BSA/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with BSA","title":"Getting help with BSA","text":"Thanks using BSA! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"https://cmatkhan.github.io/BSA/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with BSA","text":"Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! section tidyverse site.","code":""},{"path":"https://cmatkhan.github.io/BSA/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with BSA","text":"Armed reprex, next step figure ask. See also Bioconductor help website. ’s question: start community.rstudio.com, /StackOverflow. Bioconductor-related question, please ask Bioconductor Support Website using appropriate package tag (website send automatic email package authors). people answer questions. ’s bug: ’re right place, file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed.","code":""},{"path":"https://cmatkhan.github.io/BSA/SUPPORT.html","id":"what-happens-next","dir":"","previous_headings":"","what":"What happens next?","title":"Getting help with BSA","text":"efficient possible, development tidyverse packages tends bursty, shouldn’t worry don’t get immediate response. Typically don’t look repo sufficient quantity issues accumulates, ’s burst intense activity focus efforts. makes development efficient avoids expensive context switching problems, cost taking longer get back . process makes good reprex particularly important might multiple months initial report start working . can’t reproduce bug, can’t fix !","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/articles/BSA3.html","id":"comments-spaces-headings-etc","dir":"Articles","previous_headings":"","what":"comments, spaces, headings, etc","title":"BSA3","text":"","code":"library(BSA) library(tidyverse) library(foreach) library(GenomicRanges) library(BSgenome.CneoformansVarGrubiiKN99.NCBI.ASM221672v1)  kn99_genome = BSgenome.CneoformansVarGrubiiKN99.NCBI.ASM221672v1"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA3.html","id":"read-in-data-from-vcf-and-parse-into-dataframe","dir":"Articles","previous_headings":"","what":"Read in data from VCF and parse into dataframe","title":"BSA3","text":"","code":"chr_map = tibble(seqnames = seqnames(kn99_genome),                   CHR=c(seq(1:14), \"M\"))  input_paths = list(   bsa6_vcf = \"/mnt/scratch/variant_calling_pipeline/bsa/results_bsa6/variant_calling/bwamem2/vcftools/group_1_merged_dusted.recode.vcf\", #system.file(\"BSA6.IGV.vcf.gz\", package=\"BSA\"),   bsa6_meta = system.file(\"bsa6_samplesheet.rds\", package=\"BSA\") )  meta_df = readRDS(input_paths$bsa6_meta)  tmp_dir = tempdir() raw_samples_df = vcf_to_qtlseqr_table(input_paths$bsa6_vcf, \"~/Desktop\",                                        parent_ref_sample = 'KN99a',                                        parent_alt_sample = 'TDY1993',                                       parent_filter = FALSE)   samples_df = raw_samples_df %>%    left_join(chr_map) %>%    select(c(\"seqnames\", colnames(raw_samples_df)[2:length(raw_samples_df)])) %>%   dplyr::rename(CHR = seqnames) %>%    filter(!is.na(CHR)) %>%   arrange(sample, CHR, POS) %>%    left_join(meta_df) %>%   # note this!   mutate(bulk = ifelse(cond == \"inoculum\", \"low\", \"high\"))  samples_df = raw_samples_df %>%    left_join(chr_map) %>%    arrange(sample, CHR, POS) %>%    left_join(meta_df) %>%   # note this!   mutate(bulk = ifelse(cond == \"inoculum\", \"low\", \"high\"))"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"BSA6","text":"responsible installing packages prior running notebook","code":"library(BSA) library(tidyverse) library(foreach) library(GenomicRanges) library(BSgenome.CneoformansVarGrubiiKN99.NCBI.ASM221672v1)  kn99_genome = BSgenome.CneoformansVarGrubiiKN99.NCBI.ASM221672v1"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"read-in-data-from-vcf-and-parse-into-dataframe","dir":"Articles","previous_headings":"","what":"Read in data from VCF and parse into dataframe","title":"BSA6","text":"","code":"chr_map = tibble(seqnames = seqnames(kn99_genome),                   CHR=c(seq(1:14), \"M\"))  # the following file is from daniels original pipeline, which used a  # hacked together set of aligners ngm + yaha # system.file(\"BSA6.IGV.vcf.gz\", package=\"BSA\") # The example uses the bwamem2 output from the current pipeline, and is   # recommended input_paths = list(   bsa6_vcf = system.file('group_1_merged_dusted.recode.vcf.gz', package=\"BSA\"),   bsa6_meta = system.file(\"bsa6_samplesheet.rds\", package=\"BSA\") )  meta_df = readRDS(input_paths$bsa6_meta)  tmp_dir = tempdir() raw_samples_df = vcf_to_qtlseqr_table(input_paths$bsa6_vcf, \"~/Desktop\",                                        parent_ref_sample = 'KN99a',                                        parent_alt_sample = 'TDY1993',                                       parent_filter = FALSE)   samples_df = raw_samples_df %>%    left_join(chr_map) %>%    select(c(\"seqnames\", colnames(raw_samples_df)[2:length(raw_samples_df)])) %>%   dplyr::rename(CHR = seqnames) %>%    filter(!is.na(CHR)) %>%   arrange(sample, CHR, POS) %>%    left_join(meta_df) %>%   # note this!   mutate(bulk = ifelse(cond == \"inoculum\", \"low\", \"high\"))  samples_df = raw_samples_df %>%    left_join(chr_map) %>%    arrange(sample, CHR, POS) %>%    left_join(meta_df) %>%   # note this!   mutate(bulk = ifelse(cond == \"inoculum\", \"low\", \"high\")) summary(   filter(samples_df,           Filt_Genotype == \"Alternative\",           genotype != 1) %>%            select(sample, Depth, RealDepth, genotype)   ) filter(samples_df, Filt_Genotype == \"Alternative\", genotype != 1) %>%    ggplot(aes(sample, RealDepth)) +    geom_boxplot() +   ggtitle(\"Filt Genotype, VCF genotype mismatch. RealDepth Distributions\") samples_df %>%    filter(sample == \"P4L2\") %>%    pull(RealDepth) %>%   summary() samples_df %>%   filter(!is.na(group)) %>% ggplot(aes( sample, log2(Depth))) +      geom_violin(aes(fill=factor(cond))) +      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),           text = element_text(size = 20)) +   scale_y_continuous(limits = c(8,18), breaks = seq(8, 18, 1)) +     facet_grid(group~day,scales = \"free_x\")"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"split-the-data-into-two-groups","dir":"Articles","previous_headings":"","what":"Split the data into two groups","title":"BSA6","text":"oneMouse samples passed single mouse. sepMouse passed 5 separate mice.","code":"group_split = samples_df %>%   # NOTE! I didn't have the WT in my samplesheet...   filter(!is.na(group)) %>%   group_by(group) %>%   group_split()  names(group_split) = unlist(map(group_split, ~unique(pull(.,group))))  meta_df_group_split = meta_df %>%   group_by(group) %>%   group_split()  names(meta_df_group_split) =    unlist(map(meta_df_group_split, ~unique(pull(.,group))))"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"aggregate-by-pool-and-condition","dir":"Articles","previous_headings":"","what":"Aggregate by pool and condition","title":"BSA6","text":"BSA6, comparing effect passing variants single mouse vs separate mice. sets, wish examine data different levels aggregation. Hence, aggregate first pool create summed_replicate data, condition create summed_condition data.","code":"collapse_data = function(df_with_meta, grouping_conditions, sample_columns){      if(length(setdiff(grouping_conditions, colnames(df_with_meta))) > 0){     stop(sprintf(\"there is a grouping condition column which is not in the dataframe colnames\"))   }      df_with_meta %>%   # convert character vector to a vector of symbols,    # then unquote that vector of symbols with !!!   # https://stackoverflow.com/a/52572383   group_by(!!!syms(grouping_conditions)) %>%    summarize(RealDepth    = sum(RealDepth),             Depth        = sum(Depth),             Reference    = sum(Reference),             Alternative1 = sum(Alternative1),             .groups = 'keep') %>%    unite(\"sample\", !!!syms(sample_columns), remove = FALSE) %>%   group_by(sample) %>%    arrange(CHR, POS, REF_Allele, ALT1) %>%   ungroup() }  # Sum over replicates # For each given condition, the result is that there will be only one pool. So  # if we had 2 replicates per pool, there will now be only one pool of YPD at 15  # days. If there are 5 pools, each done in a different mouse, then there will be  # 5 independent records (pools) of that YPD at 15 days summed_replicates_split = map(group_split,                                collapse_data,                                c('CHR','POS','REF_Allele','ALT1',                                 'bulk','cond','pool','day'),                               c('pool', 'cond', 'day'))  summed_replicates_meta = summed_replicates_split %>%   map(select, sample, pool, cond, day) %>%    map(distinct, sample, .keep_all = TRUE)  # Sum over both replicates AND pools # This creates a single record for a given condition, eg YPD at 15 days summed_conditions_split = map(group_split,                                collapse_data,                                c('CHR','POS','REF_Allele','ALT1',                                 'bulk', 'cond','day'),                               c('cond', 'day'))  summed_conditions_meta = summed_conditions_split %>%   map(select, sample, cond, day, bulk) %>%    map(distinct, sample, .keep_all = TRUE)"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"ready-the-data-for-input-into-qtlseqr","dir":"Articles","previous_headings":"","what":"Ready the data for input into QTLseqR","title":"BSA6","text":"now need transform data format QTLseqR functions can consume. purpose picker2. Get information picker2 functions vignette like : ?picker2.","code":"# this function will run the `picker2` function on the oneMouse and sepMouse  # groups run_picker2 = function(group_name,                        metadata_split,                        sample_df,                         grouping_var,                        base_cond_in_each_group){    experiment_crosses =     sample_comparison_frame(metadata_split,                             grouping_var = grouping_var,                             base_cond_in_each_group = base_cond_in_each_group)    out = foreach(     row = iterators::iter(experiment_crosses, by='row'),     .inorder = TRUE   ) %do% {     picker2(sample_df,              low_bulk_sample = row[['lowBulk']],              high_bulk_sample = row[['highBulk']])   }   names(out) = experiment_crosses$highBulk      out }  bsa_data_sets = list(      # run picker2 on every record   no_collapse         = map(names(group_split),                              ~run_picker2(                               .,                                meta_df_group_split[[.]],                                group_split[[.]],                               grouping_var = 'pool',                               base_cond_in_each_group = TRUE)),      # previously called summedReplicatesBSA   replicates_collapse = map(names(summed_replicates_split),                             ~run_picker2(                               .,                                summed_replicates_meta[[.]],                               summed_replicates_split[[.]],                               grouping_var = 'pool',                               base_cond_in_each_group = TRUE)),    # previously called allPoolsInOneBSA   condition_collapse  = map(names(summed_conditions_split),                             ~run_picker2(                               .,                                summed_conditions_meta[[.]],                               summed_conditions_split[[.]],                               grouping_var = 'day',                               base_cond_in_each_group = FALSE))      )  names(bsa_data_sets$no_collapse)         = names(group_split)  names(bsa_data_sets$replicates_collapse) = names(summed_replicates_split)  names(bsa_data_sets$condition_collapse)  = names(summed_conditions_split)"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"run-the-qtlseqr-functions-to-calculate-the-allele-frequency-metrics","dir":"Articles","previous_headings":"","what":"Run the QTLSeqR functions to calculate the allele frequency metrics","title":"BSA6","text":"Now data aggregated different levels, since BSA6 occurs pooled samples (strains passed separate mice) oneMouse (strains passed single mouse), conduct one data sets (three levels aggregate data).","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"create-genome-windows-tiles","dir":"Articles","previous_headings":"Plotting","what":"Create genome windows (tiles)","title":"BSA6","text":"table look like :","code":"# A tibble: 18,921 × 6    CHROM      start   end width strand CHR      <chr>      <int> <int> <int> <fct>  <chr>  1 CP022321.1     1  1000  1000 *      1      2 CP022321.1  1001  2000  1000 *      1      3 CP022321.1  2001  3000  1000 *      1      4 CP022321.1  3001  4000  1000 *      1      5 CP022321.1  4001  5000  1000 *      1      6 CP022321.1  5001  6000  1000 *      1      7 CP022321.1  6001  7000  1000 *      1      8 CP022321.1  7001  8000  1000 *      1      9 CP022321.1  8001  9000  1000 *      1     10 CP022321.1  9001 10000  1000 *      1 tiled_genome_df =    tileGenome(seqlengths(kn99_genome),               tilewidth = 1000,               cut.last.tile.in.chrom = TRUE) %>%    as_tibble() %>%    left_join(chr_map) %>%   dplyr::rename(CHROM=seqnames)"},{"path":"https://cmatkhan.github.io/BSA/articles/BSA6.html","id":"section","dir":"Articles","previous_headings":"","what":"BSA6","title":"BSA6","text":"","code":"# a helper function whose purpose is to execute the `bin_variants` function # on each sample in either oneMouse or pooled_mouse sets bin_variants_by_group = function(set_name, bsa_set){   out = foreach(     sample_name = names(bsa_set),     .inorder = TRUE   ) %do% {     df = bsa_set[[sample_name]]     x = bin_variants(df,                   tiled_genome_df,                  seqlengths(kn99_genome),                  \"CHROM\") %>%       mutate(group = set_name,              sample = sample_name)   }   do.call('rbind', out) }  bin_list = list(      binned_filtered_summedReplicates =      map(       names(filtered_bsa_data_sets$replicates_collapse),        ~bin_variants_by_group(       .,filtered_bsa_data_sets$replicates_collapse[[.]])) %>%   do.call('rbind',.),      binned_filtered_summedConditions =      map(       names(filtered_bsa_data_sets$condition_collapse),        ~bin_variants_by_group(       .,filtered_bsa_data_sets$condition_collapse[[.]])) %>%     do.call('rbind', .) )   graphing_df = bin_list %>%   do.call('rbind', .) %>%   mutate(collapse_level =             ifelse(str_detect(sample, \"^\\\\d|^all\"),                   \"replicate\", \"condition\")) pool_min_max_df = graphing_df %>%    ungroup() %>%   filter(collapse_level == \"replicate\") %>%   separate(sample, c('pool', 'cond', 'day'), sep = \"_\", remove = FALSE) %>%   select(-pool) %>%   group_by(CHROM, tile, group, cond, day) %>%    summarize(pool_max_smoothed_allele_freq   = max(mean_smoothed_delta_snp, na.rm = TRUE),             pool_min_smoothed_allele_freq   = min(mean_smoothed_delta_snp, na.rm = TRUE),             pool_max_unsmoothed_allele_freq = max(mean_deltaSNP, na.rm = TRUE),             pool_min_unsmoothed_allele_freq = min(mean_deltaSNP, na.rm = TRUE),             .groups = 'keep') %>%   separate(tile, c(\"binFloor\",\"binCeiling\"), sep = \",\") %>%   ungroup() %>%   pivot_longer(starts_with(\"pool\")) %>%   mutate(min_max = paste0(\"pool_allele_freq_\", str_extract(name, \"max|min\")),          smoothed = ifelse(str_extract(name, \"smoothed|unsmoothed\") == 'smoothed', TRUE, FALSE)) %>%   select(-name) %>%   pivot_wider(names_from = min_max, values_from = value) %>%   arrange(group, cond, day, CHROM, binFloor) %>%   arrange(smoothed) %>%   select(group,cond,day, CHROM,binFloor,binCeiling,smoothed,           pool_allele_freq_min, pool_allele_freq_max) %>%   mutate(binFloor = as.numeric(binFloor), binCeiling = as.numeric(binCeiling))  condition_collapsed_df = graphing_df %>%   ungroup() %>%   filter(collapse_level == \"condition\") %>%    separate(sample, c('cond', 'day'), sep = \"_\", remove = FALSE) %>%   select(group,cond,day,significance, CHROM, binFloor, binCeiling, binMiddle, mean_deltaSNP, mean_smoothed_delta_snp) %>%   pivot_longer(c(mean_deltaSNP, mean_smoothed_delta_snp)) %>%   mutate(smoothed = ifelse(str_detect(name, \"smoothed\"), TRUE, FALSE)) %>%   dplyr::rename(condition_allele_freq=value) %>%   select(-name) %>%   arrange(group, cond, day, CHROM, binFloor) %>%   arrange(smoothed) %>%   select(group,cond,day,significance, CHROM,binFloor,           binCeiling,smoothed, condition_allele_freq)  x = pool_min_max_df %>%     mutate(binFloor = as.numeric(binFloor), binCeiling = as.numeric(binCeiling)) %>%   left_join(condition_collapsed_df) %>%   filter(complete.cases(.)) %>%   mutate(binMiddle = (binFloor+binCeiling )/ 2) %>%     select(group,cond,day,significance, CHROM,binFloor,           binCeiling,binMiddle,smoothed,pool_allele_freq_min,           pool_allele_freq_max, condition_allele_freq)   # TODO this needs to be checked #The SNPindex.LOW should be the same for YPD and Lungs.... MaxAndMins = filtered_bsa_data_sets$condition_collapse$sepMouse$ypd_1 %>%    select(c(CHROM,POS,REF,ALT, SNPindex.LOW)) %>%   mutate(min_SNPchange = -1*SNPindex.LOW, max_SNPchange = 1-SNPindex.LOW) %>%    select(-SNPindex.LOW)  #This mutation was erased in the addition of the drug marker in the C8 parent (It was in the arm). MaxAndMins=MaxAndMins %>%    filter(!(CHROM==\"chr2\" &               (POS==283162 | POS==283652|                  (POS>466000 & POS<467000)))) chr_name = \"CP022322.1\"  x %>%   filter(CHROM==chr_name, cond %in% c(\"lung\", \"ypd\"), smoothed == TRUE) %>%   unite(\"combine\", cond,significance, remove = FALSE) %>%   ggplot(aes(binMiddle/1000, condition_allele_freq)) +     geom_line(data = filter(MaxAndMins, CHROM == chr_name), aes(POS/1000, min_SNPchange)) +     geom_line(data = filter(MaxAndMins, CHROM == chr_name), aes(POS/1000, max_SNPchange)) +     geom_pointrange(aes(ymin=pool_allele_freq_min,                         ymax=pool_allele_freq_max,                         x=binMiddle/1000,                         y=condition_allele_freq,                         size=combine,                         colour=combine,                         alpha=combine,                         order=\"combine\"), na.rm = TRUE) +     scale_size_manual(name=\"Condition and significance\",                       labels=c(\"Lung, not significant\",\"YPD, not significant\",\"Lung, significant\",  \"YPD, significant\"),                       values = c(0.1,0.1,0.4, 0.4), drop=F)+     scale_colour_manual(name=\"Condition and significance\",                         labels=c(\"Lung, not significant\",\"YPD, not significant\",\"Lung, significant\",  \"YPD, significant\"),                         values = c('lung_0'=\"red\",'ypd_0'=\"black\",                                    'lung_1'=\"red\",'lung_1'=\"black\"), drop=F)+     scale_alpha_manual(name=\"Condition and significance\",                        labels=c(\"Lung, not significant\",\"YPD, not significant\",\"Lung, significant\",  \"YPD, significant\"),                        values = c(0.95,0.95,1, 1), drop=F)+     labs(title=paste0(\"Chromosome \", chr_name), x=paste0(\"Position on chromosome \",chr_name,\" (kb)\"),y=\"Change in allele frequency (BSA)\", color=\"Pool\")+     geom_hline(yintercept = c(0), color=\"black\", size=0.6)+     scale_x_continuous(breaks = seq(from=0, to=2400, by=300), limits=c(0, 2400),expand = c(0, 0))+     scale_y_continuous(breaks = c(-1,-0.75,-0.5, -0.25, 0,0.25,0.5,0.75,1), limits = c(-1.05,1.05), expand = c(0,0))+     theme(#legend.title = element_text(size=18),       legend.position = \"right\",       plot.title = element_blank(),       legend.text = element_text(size=16),       axis.title=element_text(size=32),       axis.title.y =element_text(margin = margin(r=25, t=0, l=5, b=0)),       axis.title.x =element_text(margin = margin(r=0, t=25, l=0, b=5)),       axis.text=element_text(size = 28),       axis.ticks.length = unit(0.3,\"cm\"),       panel.grid.major=element_blank(),       panel.grid.minor=element_blank(),       panel.background = element_rect(fill = \"white\",colour = \"black\", size=1),       text=element_text(family=\"sans\"))+     facet_grid(day~group) x %>%   filter(CHROM==chr_name, cond %in% c(\"lung\", \"ypd\"), smoothed == TRUE) %>%   unite(\"combine\", cond,significance, remove = FALSE) %>%   ggplot(aes(binMiddle/1000, condition_allele_freq)) +     geom_line(data = filter(MaxAndMins, CHROM == chr_name), aes(POS/1000, min_SNPchange)) +     geom_line(data = filter(MaxAndMins, CHROM == chr_name), aes(POS/1000, max_SNPchange)) +     geom_pointrange(aes(ymin=pool_allele_freq_min,                         ymax=pool_allele_freq_max,                         x=binMiddle/1000,                         y=condition_allele_freq,                         size=combine,                         colour=group,                         alpha=combine,                         order=\"combine\"), na.rm = TRUE) +     scale_size_manual(name=\"Condition and significance\",                       labels=c(\"Lung, not significant\",\"YPD, not significant\",\"Lung, significant\",  \"YPD, significant\"),                       values = c(0.1,0.1,0.4, 0.4), drop=F)+     # scale_colour_manual(name=\"Condition and significance\",     #                     labels=c(\"Lung, not significant\",\"YPD, not significant\",\"Lung, significant\",  \"YPD, significant\"),     #                     values = c('lung_0'=\"red\",'ypd_0'=\"black\",     #                                'lung_1'=\"red\",'lung_1'=\"black\"), drop=F)+     scale_alpha_manual(name=\"Condition and significance\",                        labels=c(\"Lung, not significant\",\"YPD, not significant\",\"Lung, significant\",  \"YPD, significant\"),                        values = c(0.95,0.95,1, 1), drop=F)+     labs(title=paste0(\"Chromosome \", chr_name), x=paste0(\"Position on chromosome \",chr_name,\" (kb)\"),y=\"Change in allele frequency (BSA)\", color=\"Pool\")+     geom_hline(yintercept = c(0), color=\"black\", size=0.6)+     scale_x_continuous(breaks = seq(from=0, to=2400, by=300), limits=c(0, 2400),expand = c(0, 0))+     scale_y_continuous(breaks = c(-1,-0.75,-0.5, -0.25, 0,0.25,0.5,0.75,1), limits = c(-1.05,1.05), expand = c(0,0))+     theme(#legend.title = element_text(size=18),       legend.position = \"right\",       plot.title = element_blank(),       legend.text = element_text(size=16),       axis.title=element_text(size=32),       axis.title.y =element_text(margin = margin(r=25, t=0, l=5, b=0)),       axis.title.x =element_text(margin = margin(r=0, t=25, l=0, b=5)),       axis.text=element_text(size = 28),       axis.ticks.length = unit(0.3,\"cm\"),       panel.grid.major=element_blank(),       panel.grid.minor=element_blank(),       panel.background = element_rect(fill = \"white\",colour = \"black\", size=1),       text=element_text(family=\"sans\"))+     facet_grid(~day)"},{"path":"https://cmatkhan.github.io/BSA/articles/CreatePipelineSamplesheet.html","id":"processing-pipeline-sample-sheet","dir":"Articles","previous_headings":"","what":"Processing Pipeline sample sheet","title":"CreatePipelineSamplesheet","text":"Currently, fields actually used processing pipeline. , part work progress standardize metadata surrounding BSA experiment analysis may automated. Daniel’s metadata, columns contain one piece information – eg, Strain Alias erroneous P, integer describing mouse, period, integer describing replicate, letter describing tissue (currently called condition table described ). fields also consistent – eg, parsing needs happen BSA2 different BSA6. sample (unique name) group (used process bam files together variant calling step. group 0 signifies file processed individually. number may used identify groups, eg 5 files, one file processed individually, groups 2, group might look like 0,1,1,2,2. Note bam files processed individually default) pool (pool sample originates. unique across pools, eg P1-P5 Pall) replicate (replicate given pool, eg 1,2,3) day (number days passed time course harvest) cond (culture condition, eg inoculum, lung, brain, ypd) experiment (unique identifier experiment, eg BSA6) runNumber (sequencer, eg 4726) fastq_1 paths fastq files fastq_2 paths fastq files creating samplesheet, , need move data lts scratch. assumption ’ll make directory store BSA pipeline output, directory, ’ll make subdirectory called data. , launch pipeline within experiment directory (level data directory) relative path data fastq file correct.","code":""},{"path":"https://cmatkhan.github.io/BSA/articles/CreatePipelineSamplesheet.html","id":"bsa2","dir":"Articles","previous_headings":"","what":"BSA2","title":"CreatePipelineSamplesheet","text":"","code":"bsa2_df = read_excel(system.file(\"DanielSeqDatabase.xlsx\", package = \"BSA\")) %>%   filter(str_detect(Description,'BSA2')) %>%   mutate(pool = str_remove(str_extract(`Strain Alias`, \"P\\\\d\"), \"P\"),          replicate = str_remove(str_remove(`Strain Alias`, \"P\\\\d\\\\.\"), \"\\\\w$\"),          day = 'na',          cond = str_extract(`Strain Alias`, \"\\\\w$\"),          experiment = str_remove_all(str_replace(Experiment, \"-\", \"_\"), \" \")) %>%   dplyr::rename(runNumber = `Run number`) %>%   mutate(fastq_1 = file.path(FileFolder,FirstPairFileName)) %>%   dplyr::rename(sample = `Strain Alias`) %>%   mutate(fastq_2 = str_replace(fastq_1, \"_R1_\", \"_R2_\")) %>%   mutate(fastq_1 = file.path(\"data\",basename(fastq_1)),          fastq_2 = file.path(\"data\",basename(fastq_2))) %>%   # set the group back to 1 -- process all together   mutate(group = 1) %>%   dplyr::select(sample,group, pool, cond, day, replicate, experiment,                  runNumber, fastq_1, fastq_2)  reference_strain_df = tibble(   sample = c(\"KN99a\", \"TDY1993\"),   group  = c(1,1),   pool   = c(1,1),   cond   = c(1,1),   day    = c(1,1),   replicate = c(1,1),   experiment =  c(1,1),   runNumber = c(2553, 3153),   fastq_1 = c('data/2553_Brent_KN99aaa_GTAC13_GAGGCGTATC_S13_R1_001.fastq.gz',               'data/3153_Brent_TDY1993_GTAC_33_SIC_Index2_09_ACCATAC_TGTGAG_S70_R1_001.fastq.gz'),   fastq_2 = c('data/2553_Brent_KN99aaa_GTAC13_GAGGCGTATC_S13_R2_001.fastq.gz',               'data/3153_Brent_TDY1993_GTAC_33_SIC_Index2_09_ACCATAC_TGTGAG_S70_R2_001.fastq.gz') )  df = rbind(bsa2_df, reference_strain_df)  # write out csv # write_csv(df, \"/path/to/someplace/bsa2_samplesheet.csv\")"},{"path":"https://cmatkhan.github.io/BSA/articles/CreatePipelineSamplesheet.html","id":"bsa6","dir":"Articles","previous_headings":"","what":"BSA6","title":"CreatePipelineSamplesheet","text":"","code":"relevel_cond = function(cond){   switch (cond,   L = \"lung\",   Y = \"ypd\",   B = \"brain\",   I = \"inoculum\" ) }   df = readRDS(system.file(\"bsa6_raw_meta.rds\", package = \"BSA\")) %>%   mutate(pool = ifelse(str_detect(`Strain Alias`, \"all\"),                         \"all\",                         str_remove(str_extract(`Strain Alias`, \"^P\\\\d\"), \"^P\"))) %>%   mutate(tmp = str_remove(`Strain Alias`, paste0(\"P\", pool))) %>%   mutate(cond = ifelse(substr(tmp,1,1) == \"1\", NA, substr(tmp,1,1))) %>%   mutate(day = ifelse(is.na(cond), 15, 8)) %>%   mutate(tmp = str_remove(tmp, as.character(day))) %>%   mutate(cond = ifelse(is.na(cond), substr(tmp,1,1), cond)) %>%   mutate(day = ifelse(day == 8 & cond == \"Y\", 1, day)) %>%   mutate(day = ifelse(day == 8 & cond == \"I\", 0, day)) %>%   mutate(tmp = str_remove(tmp,cond)) %>%   dplyr::rename(replicate = tmp) %>%   mutate(replicate = ifelse(replicate == \"\", 1,replicate)) %>%   dplyr::rename(runNumber = `Run number`) %>%   mutate(Experiment = str_remove_all(str_replace(Experiment, \"-\", \"_\"), \" \")) %>%   dplyr::rename(experiment = Experiment) %>%   mutate(fastq_1 = file.path(FileFolder,FirstPairFileName)) %>%   dplyr::rename(sample = `Strain Alias`) %>%   mutate(group = ifelse(str_detect(sample, \"all\"), \"oneMouse\", \"sepMouse\")) %>%   mutate(fastq_2 = str_replace(fastq_1, \"_R1_\", \"_R2_\")) %>%   mutate(cond = unlist(map(cond, relevel_cond))) %>%   dplyr::select(sample,group, pool, cond, day, replicate, experiment,                  runNumber, fastq_1, fastq_2) %>%   mutate(fastq_1 = file.path(\"data\",basename(fastq_1)),          fastq_2 = file.path(\"data\",basename(fastq_2))) %>%   # set the group back to 1 -- process all together   mutate(group = 1)  reference_strain_df = tibble(   sample = c(\"KN99a\", \"TDY1993\"),   group  = c(1,1),   pool   = c(1,1),   cond   = c(1,1),   day    = c(1,1),   replicate = c(1,1),   experiment =  c(1,1),   runNumber = c(2553, 3153),   fastq_1 = c('data/2553_Brent_KN99aaa_GTAC13_GAGGCGTATC_S13_R1_001.fastq.gz',               'data/3153_Brent_TDY1993_GTAC_33_SIC_Index2_09_ACCATAC_TGTGAG_S70_R1_001.fastq.gz'),   fastq_2 = c('data/2553_Brent_KN99aaa_GTAC13_GAGGCGTATC_S13_R2_001.fastq.gz',               'data/3153_Brent_TDY1993_GTAC_33_SIC_Index2_09_ACCATAC_TGTGAG_S70_R2_001.fastq.gz') )  df = rbind(df, reference_strain_df)  #write_csv(df, \"/mnt/scratch/variant_calling_pipeline/bsa6_samplesheet.csv\") #write_tsv(df, \"/mnt/scratch/variant_calling_pipeline/bsa6_samplesheet.tsv\") df"},{"path":"https://cmatkhan.github.io/BSA/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Agustihno. Author, maintainer. Chase Mateusiak. Author.","code":""},{"path":"https://cmatkhan.github.io/BSA/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Agustihno, Daniel (2023). “Daniel's paper placeholder.” bioRxiv. doi:10.1101/TODO, https://www.biorxiv.org/content/10.1101/TODO.","code":"@Article{,   title = {Daniel's paper placeholder},   author = {{Agustihno} and {Daniel}},   year = {2023},   journal = {bioRxiv},   doi = {10.1101/TODO},   url = {https://www.biorxiv.org/content/10.1101/TODO}, }"},{"path":"https://cmatkhan.github.io/BSA/index.html","id":"bsa","dir":"","previous_headings":"","what":"Conduct c.neoformans BSA analysis","title":"Conduct c.neoformans BSA analysis","text":"goal BSA reimplement Daniel’s BSA2 code package structure may installed using R install. may also form seed either software workflow package bioconductor.","code":""},{"path":"https://cmatkhan.github.io/BSA/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Conduct c.neoformans BSA analysis","text":"","code":"install.packages(\"remotes\")  remotes::install_github(\"cmatKhan/BSA\")"},{"path":"https://cmatkhan.github.io/BSA/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Conduct c.neoformans BSA analysis","text":"first thing need iscreate samplesheet process data BSA processing pipeline. Instructions creating samplesheet Article () called CreatePipelineSampleSheet. Next, using functions package analyze data. example process BSA3 BSA6.","code":""},{"path":"https://cmatkhan.github.io/BSA/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Conduct c.neoformans BSA analysis","text":"citation output using citation('BSA') R. Please run check updates cite BSA. Please note BSA made possible thanks many R bioinformatics software authors, cited either vignettes /paper(s) describing package.","code":"print(citation('BSA'), bibtex = TRUE) #> To cite package 'BSA' in publications use: #>  #>   Agustihno, Daniel (2023). \"Daniel's paper placeholder.\" _bioRxiv_. , #>   <https://www.biorxiv.org/content/10.1101/TODO>. #>  #> A BibTeX entry for LaTeX users is #>  #>   @Article{, #>     title = {Daniel's paper placeholder}, #>     author = {{Agustihno} and {Daniel}}, #>     year = {2023}, #>     journal = {bioRxiv}, #>     doi = {10.1101/TODO}, #>     url = {https://www.biorxiv.org/content/10.1101/TODO}, #>   }"},{"path":"https://cmatkhan.github.io/BSA/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Conduct c.neoformans BSA analysis","text":"Please note BSA project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://cmatkhan.github.io/BSA/index.html","id":"development-tools","dir":"","previous_headings":"","what":"Development tools","title":"Conduct c.neoformans BSA analysis","text":"Continuous code testing possible thanks GitHub actions usethis, remotes, rcmdcheck customized use Bioconductor’s docker containers BiocCheck. Code coverage assessment possible thanks codecov covr. documentation website automatically updated thanks pkgdown. code styled automatically thanks styler. documentation formatted thanks devtools roxygen2. details, check dev directory. package developed using biocthis.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/analyzer.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze stuff — analyzer","title":"Analyze stuff — analyzer","text":"Now list comparisons replicates (object: \"replicates\"), pools (object: \"pools\") samples together (allPoolsInOneComparison) can begin filtering samples. First idea filter following params","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/analyzer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze stuff — analyzer","text":"","code":"analyzer(   SNPcomparison,   minDepthPercentile = 0.1,   maxDepthPercentile = 0.9,   windowSize = 25000,   bulkSize = 20,   outlierFilt = \"deltaSNP\",   filter_chr_list = NULL )"},{"path":"https://cmatkhan.github.io/BSA/reference/analyzer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze stuff — analyzer","text":"SNPcomparison lower tenth percentile > quantile(sum depth bulks, na.rm = T, probs = 0.1)) minDepthPercentile sample depth - Half min depth, Default: 0.9 maxDepthPercentile depth: higher fifth percentile > quantile(sum depth bulks, na.rm = T, probs = 0.95)), Default: 0.1 windowSize PARAM_DESCRIPTION, Default: 25000 bulkSize PARAM_DESCRIPTION, Default: 20 outlierFilt see QTLseqR::runGprimeAnalysis, Default: 'deltaSNP' filter_chr_list list chromosome names exclude, Default: NULL","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/analyzer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze stuff — analyzer","text":"filtered dataframe","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/analyzer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyze stuff — analyzer","text":"DETAILS","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/bin_variants.html","id":null,"dir":"Reference","previous_headings":"","what":"Bin Variants — bin_variants","title":"Bin Variants — bin_variants","text":"Calculate statistics bins (genome tiles)","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/bin_variants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bin Variants — bin_variants","text":"","code":"bin_variants(   variant_metrics_df,   tiled_genome_df,   chr_seqlengths,   chr_colname,   qvalue_lower_thres = 0.1,   qvalue_upper_thres = 0.5 )"},{"path":"https://cmatkhan.github.io/BSA/reference/bin_variants.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bin Variants — bin_variants","text":"variant_metrics_df PARAM_DESCRIPTION tiled_genome_df PARAM_DESCRIPTION chr_seqlengths PARAM_DESCRIPTION chr_colname PARAM_DESCRIPTION qvalue_lower_thres PARAM_DESCRIPTION, Default: 0.1 qvalue_upper_thres PARAM_DESCRIPTION, Default: 0.5","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/bin_variants.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bin Variants — bin_variants","text":"OUTPUT_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/bin_variants.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bin Variants — bin_variants","text":"DETAILS","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/reference/bin_variants.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bin Variants — bin_variants","text":"","code":"if (FALSE) { if(interactive()){  #EXAMPLE1  } }"},{"path":"https://cmatkhan.github.io/BSA/reference/getG_local.html","id":null,"dir":"Reference","previous_headings":"","what":"get G prime stat — getG_local","title":"get G prime stat — getG_local","text":"function used runGprimeAnalysis_local calculate G statisic G defined equation: $$G = 2*\\sum_{=1}^{4}n_{}*ln\\frac{obs(n_i)}{exp(n_i)}$$ SNP, \\(n_i\\) = 1 4 corresponds reference alternate allele depths bulk, described following table: ...\\(obs(n_i)\\) observed allele depths described data frame. Method 1 calculates G statistic using expected values assuming read depth equal alleles bulks: $$exp(n_1) = ((n_1 + n_2)*(n_1 + n_3))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_2) = ((n_2 + n_1)*(n_2 + n_4))/(n_1 + n_2 + n_3 + n_4)$$ etc...","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/getG_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get G prime stat — getG_local","text":"","code":"getG_local(LowRef, HighRef, LowAlt, HighAlt)"},{"path":"https://cmatkhan.github.io/BSA/reference/getG_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get G prime stat — getG_local","text":"LowRef vector reference allele depth low bulk HighRef vector reference allele depth high bulk LowAlt vector alternate allele depth low bulk HighAlt vector alternate allele depth high bulk","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/getG_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get G prime stat — getG_local","text":"vector G statistic values length ","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/getG_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"get G prime stat — getG_local","text":"DETAILS","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/reference/getPvals_local.html","id":null,"dir":"Reference","previous_headings":"","what":"get g prime pvals — getPvals_local","title":"get g prime pvals — getPvals_local","text":"function used runGprimeAnalysis_local estimate p-values weighted G' statistic based non-parametric estimation method described Magwene et al. 2011. Breifly, using natural log Gprime median absolute deviation (MAD) calculated. Gprime set trimmed exclude outlier regions (.e. QTL) based Hampel's rule. alternate method filtering QTL proposed using absolute delta SNP indeces greater set threshold filter potential QTL. estimation mode trimmed set calculated using mlv function package modeest. Finally, mean variance set estimated using median mode p-values estimated log normal distribution.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/getPvals_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get g prime pvals — getPvals_local","text":"","code":"getPvals_local(   Gprime,   deltaSNP = NULL,   outlierFilter = c(\"deltaSNP\", \"Hampel\"),   filterThreshold )"},{"path":"https://cmatkhan.github.io/BSA/reference/getPvals_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get g prime pvals — getPvals_local","text":"Gprime vector G prime values (tricube weighted G statistics) deltaSNP vector delta SNP values use QTL region filtering outlierFilter one either \"deltaSNP\" \"Hampel\". Method filtering outlier (ie QTL) regions p-value estimation filterThreshold absolute delta SNP index use filter putative QTL","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/getPvals_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get g prime pvals — getPvals_local","text":"OUTPUT_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/getPvals_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"get g prime pvals — getPvals_local","text":"DETAILS","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/picker2.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform VCF Table for QTLseqR — picker2","title":"Transform VCF Table for QTLseqR — picker2","text":"Function set comparisons two samples output table way QTLseq package can use. Uses two element list create table can used package QTLseq.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/picker2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform VCF Table for QTLseqR — picker2","text":"","code":"picker2(   samples_with_meta_df,   low_bulk_sample,   high_bulk_sample,   sample_col = \"sample\",   bulk_col = \"bulk\" )"},{"path":"https://cmatkhan.github.io/BSA/reference/picker2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform VCF Table for QTLseqR — picker2","text":"samples_with_meta_df dataframe representing samples vcf_to_qtlseqr_table joined sample metadata low_bulk_sample String. name sample (element vcf_df list) corresponding Low Bulk. high_bulk_sample name sample (element vcf_df list) corresponding High Bulk. sample_col name column sample names. Must contain low_bulk_sample high_bulk_sample. Default 'sample'. bulk_col name column stores different sample comparisons. bulk name retained QTLSeqR traditional BSA experiments","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/picker2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform VCF Table for QTLseqR — picker2","text":"data.frame format can understood QTLseq.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/picker2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform VCF Table for QTLseqR — picker2","text":"format used QTLseq package. Picker2 adaptations picker 1 tabler function awk. RealDepth instead realDepth, Alt2 allele.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://cmatkhan.github.io/BSA/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runGprimeAnalysis_local.html","id":null,"dir":"Reference","previous_headings":"","what":"QTLseqr like G prime analysis — runGprimeAnalysis_local","title":"QTLseqr like G prime analysis — runGprimeAnalysis_local","text":"Identify QTL using smoothed G statistic","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runGprimeAnalysis_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QTLseqr like G prime analysis — runGprimeAnalysis_local","text":"","code":"runGprimeAnalysis_local(   SNPset,   windowSize = 1e+06,   outlierFilter = \"deltaSNP\",   filterThreshold = 0.1,   ... )"},{"path":"https://cmatkhan.github.io/BSA/reference/runGprimeAnalysis_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QTLseqr like G prime analysis — runGprimeAnalysis_local","text":"SNPset Data frame SNP set containing previously filtered SNPs windowSize window size (base pairs) bracketing SNP calculate statitics. Magwene et. al recommend window size ~25 cM, also recommend optionally trying several window sizes test peaks - undersmoothed. Default: 1e+06 outlierFilter one either \"deltaSNP\" \"Hampel\". Method filtering outlier (ie QTL) regions p-value estimation. Default: 'deltaSNP' filterThreshold absolute delta SNP index use filter putative QTL (default = 0.1) ... arguments passed locfit subsequently locfit.raw() (lfproc). Usefull cases get \"vertex space warnings\"; Set maxk higher default 100. See locfit.raw(). getting warning seriously consider increasing window size. Default: 0.1","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runGprimeAnalysis_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"QTLseqr like G prime analysis — runGprimeAnalysis_local","text":"supplied SNP set tibble G' analysis. Includes five new columns: Gprime - tricube smoothed G statistic based supplied window size pvalue - pvalue SNP calculatd non-parametric estimation negLog10Pval - -Log10(pvalue) supplied quick plotting qvalue - Benajamini-Hochberg adjusted p-value","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runGprimeAnalysis_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"QTLseqr like G prime analysis — runGprimeAnalysis_local","text":"wrapper functions perform full G prime analysis identify QTL. following steps performed: 1) Genome-wide G statistics calculated getG.  G defined equation: $$G = 2*\\sum_{=1}^{4} n_{}*ln\\frac{obs(n_i)}{exp(n_i)}$$ SNP, \\(n_i\\) = 1 4 corresponds reference alternate allele depths bulk, described following table: ...\\(obs(n_i)\\) observed allele depths described data frame. getG calculates G statistic using expected values assuming read depth equal alleles bulks: $$exp(n_1) = ((n_1 + n_2)*(n_1 + n_3))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_2) = ((n_2 + n_1)*(n_2 + n_4))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_3) = ((n_3 + n_1)*(n_3 + n_4))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_4) = ((n_4 + n_2)*(n_4 + n_3))/(n_1 + n_2 + n_3 + n_4)$$ 2) G' tricube-smoothed G statistic predicted local regression within chromosome using tricubeStat. works weighted average across neighboring SNPs accounts Linkage disequilibrium (LD) minizing noise attributed SNP calling errors. G values neighboring SNPs within window weighted physical distance focal SNP.  3) P-values estimated based using non-parametric method described Magwene et al. 2011 function getPvals. Breifly, using natural log Gprime median absolute deviation (MAD) calculated. Gprime set trimmed exclude outlier regions (.e. QTL) based Hampel's rule. alternate method filtering QTL proposed using absolute delta SNP indeces greater 0.1 filter potential QTL. estimation mode trimmed set calculated using mlv function package modeest. Finally, mean variance set estimated using median mode p-values estimated log normal distribution.  4) Negative Log10- Benjamini-Hochberg adjusted p-values calculated using p.adjust","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runQTLseqAnalysis_local.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","title":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","text":"wrapper functions perform full G prime analysis identify QTL. following steps performed: 1) Genome-wide G statistics calculated getG.  G defined equation: $$G = 2*\\sum_{=1}^{4} n_{}*ln\\frac{obs(n_i)}{exp(n_i)}$$ SNP, \\(n_i\\) = 1 4 corresponds reference alternate allele depths bulk, described following table: ...\\(obs(n_i)\\) observed allele depths described data frame. getG calculates G statistic using expected values assuming read depth equal alleles bulks: $$exp(n_1) = ((n_1 + n_2)*(n_1 + n_3))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_2) = ((n_2 + n_1)*(n_2 + n_4))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_3) = ((n_3 + n_1)*(n_3 + n_4))/(n_1 + n_2 + n_3 + n_4)$$ $$exp(n_4) = ((n_4 + n_2)*(n_4 + n_3))/(n_1 + n_2 + n_3 + n_4)$$ 2) G' tricube-smoothed G statistic predicted local regression within chromosome using tricubeStat. works weighted average across neighboring SNPs accounts Linkage disequilibrium (LD) minizing noise attributed SNP calling errors. G values neighboring SNPs within window weighted physical distance focal SNP.  3) P-values estimated based using non-parametric method described Magwene et al. 2011 function getPvals. Breifly, using natural log Gprime median absolute deviation (MAD) calculated. Gprime set trimmed exclude outlier regions (.e. QTL) based Hampel's rule. alternate method filtering QTL proposed using absolute delta SNP indeces greater 0.1 filter potential QTL. estimation mode trimmed set calculated using mlv function package modeest. Finally, mean variance set estimated using median mode p-values estimated log normal distribution.  4) Negative Log10- Benjamini-Hochberg adjusted p-values calculated using p.adjust","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runQTLseqAnalysis_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","text":"","code":"runQTLseqAnalysis_local(   SNPset,   windowSize = 1e+06,   popStruc = \"F2\",   bulkSize,   depth = NULL,   replications = 10000,   filter = 0.3,   intervals = c(95, 99),   chrom_col = \"CHROM\",   coordinate_col = \"POS\",   delta_snp_col = \"deltaSNP\",   dp_low_col = \"DP.LOW\",   dp_high_col = \"DP.HIGH\" )"},{"path":"https://cmatkhan.github.io/BSA/reference/runQTLseqAnalysis_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","text":"SNPset Data frame SNP set containing previously filtered SNPs windowSize window size (base pairs) bracketing SNP calculate statitics. Magwene et. al recommend window size ~25 cM, also recommend optionally trying several window sizes test peaks - undersmoothed. popStruc population structure. Defaults \"F2\" assumes \"RIL\" otherwise. bulkSize non-negative integer vector. number individuals simulated bulk. Can length 1, bulks set size. Assumes first value vector simulated high bulk. depth calculated script, usually. input QTLSeqR function simulateConfInt_local replications integer. number bootstrap replications. filter numeric. minimum SNP-index filter intervals confidence intervals -- note part daniel's additional code QTLseqR package chrom_col name column stores chromosome label. Default CHROM coordinate_col name column stores snp coordinate. Default POS delta_snp_col name column stores change allele frequency. Default deltaSNP dp_low_col name column stores dp_low value. Default DP.LOW dp_high_col name column stores dp_high value. Default DP.HIGH","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runQTLseqAnalysis_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","text":"supplied SNP set tibble G' analysis. Includes five new columns: Gprime - tricube smoothed G statistic based supplied window size pvalue - pvalue SNP calculatd non-parametric estimation negLog10Pval - -Log10(pvalue) supplied quick plotting qvalue - Benajamini-Hochberg adjusted p-value","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runQTLseqAnalysis_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","text":"DETAILS","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/runQTLseqAnalysis_local.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Identify QTL using a smoothed G statistic — runQTLseqAnalysis_local","text":"NEARLY VERBATIM COPY QTLseqR","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Sample Comparison Frame — sample_comparison_frame","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"Create dataframe describes comparisons given condition conditions described pool dataframe","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"","code":"sample_comparison_frame(   pool_df,   grouping_var = \"batch\",   condition_var = \"cond\",   base_comparison_condition = \"inoculum\",   var1_name = \"lowBulk\",   var2_name = \"highBulk\",   base_cond_in_each_group = TRUE )"},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"pool_df dataframe describes pool grouping_var column group split dataframe, Default: 'batch' condition_var column describes various conditions sample, eg tissue, levels column might c(lung, brain, YPD, inoculum), Default: 'cond' base_comparison_condition condition compare conditions, Default: 'inoculum' var1_name output frame two columns, first storing samples correspond base_comparison_condition, sample conditions, Default: 'lowBulk' var2_name var1_name, rename second column output frame, Default: 'highBulk' base_cond_in_each_group whether include base condition group. Default TRUE","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"two column dataframe first column condition sample conditions group compared. example structure :","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"prepares samples QTLseqr","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"chase mateusiak","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/sample_comparison_frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Sample Comparison Frame — sample_comparison_frame","text":"","code":"if(interactive()){    library(dplyr)    # NOTE! \"P2.1I\" is a singleton     sample_example = c(\"P1.1I\",\"P1.1L\",\"P1.1Y\",                   \"P1.2B\",\"P1.2I\",\"P1.2L\",\"P1.2Y\",\"P2.1I\")     pool_construction = tibble(sample = sample_example) %>%     mutate(batch = str_remove(sample, \"\\\\w$\")) %>%    mutate(cond = ifelse(str_detect(sample, \"P[[:alnum:]].{1,3}I\"),'inoculum', NA)) %>%    mutate(cond = ifelse(str_detect(sample, \"P[[:alnum:]].{1,3}Y\"),'ypd', cond)) %>%    mutate(cond = ifelse(str_detect(sample, \"P[[:alnum:]].{1,3}L\"),'lung', cond)) %>%    mutate(cond = ifelse(str_detect(sample, \"P[[:alnum:]].{1,3}B\"),'brain', cond)) %>%    mutate(bulk = ifelse(cond == \"inoculum\", 'low', 'high'))    sample_comparison_frame(pool_construction)  }"},{"path":"https://cmatkhan.github.io/BSA/reference/set_genotype.html","id":null,"dir":"Reference","previous_headings":"","what":"Set Filt_Genotype column — set_genotype","title":"Set Filt_Genotype column — set_genotype","text":"internal helper function create Filt_Genotype column. note column name Daniel's original BSA analysis. just means column calls genotype based frequency allele RealDepth, bases pass variant caller thresholds exist (missing CIGAR), denominator. Currently three levels may returned lowDepth, Rerence Alterantive.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/set_genotype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set Filt_Genotype column — set_genotype","text":"","code":"set_genotype(depth, ref_freq, depth_thres, ref_freq_thres)"},{"path":"https://cmatkhan.github.io/BSA/reference/set_genotype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set Filt_Genotype column — set_genotype","text":"depth depth given variant, given position ref_freq frequency given variant, given position depth_thres less depth threshold, .na(depth), return value lowDepth ref_freq_thres ref greater equal number, depth passes threshold, call genotype Reference. note genotype called Alternative passes depth threshold ref_freq less equal 1 - ref_freq_thres. depth depth_thres, return lowDepth","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/set_genotype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set Filt_Genotype column — set_genotype","text":"one undefinedGenotype, lowDepth, Reference, Alternative","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateConfInt_local.html","id":null,"dir":"Reference","previous_headings":"","what":"a simulate function — simulateConfInt_local","title":"a simulate function — simulateConfInt_local","text":"FUNCTION_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateConfInt_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a simulate function — simulateConfInt_local","text":"","code":"simulateConfInt_local(   SNPset,   popStruc = \"F2\",   bulkSize,   depth = 1:100,   replications = 10000,   filter = 0.3,   intervals = c(0.05, 0.025) )"},{"path":"https://cmatkhan.github.io/BSA/reference/simulateConfInt_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a simulate function — simulateConfInt_local","text":"SNPset PARAM_DESCRIPTION popStruc PARAM_DESCRIPTION, Default: 'F2' bulkSize PARAM_DESCRIPTION depth PARAM_DESCRIPTION, Default: 1:100 replications PARAM_DESCRIPTION, Default: 10000 filter PARAM_DESCRIPTION, Default: 0.3 intervals PARAM_DESCRIPTION, Default: c(0.05, 0.025)","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateConfInt_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"a simulate function — simulateConfInt_local","text":"OUTPUT_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateConfInt_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"a simulate function — simulateConfInt_local","text":"DETAILS","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateSNPindex_local.html","id":null,"dir":"Reference","previous_headings":"","what":"simulate snp index — simulateSNPindex_local","title":"simulate snp index — simulateSNPindex_local","text":"FUNCTION_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateSNPindex_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simulate snp index — simulateSNPindex_local","text":"","code":"simulateSNPindex_local(   depth,   altFreq1,   altFreq2,   replicates = 10000,   filter = NULL )"},{"path":"https://cmatkhan.github.io/BSA/reference/simulateSNPindex_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"simulate snp index — simulateSNPindex_local","text":"depth PARAM_DESCRIPTION altFreq1 PARAM_DESCRIPTION altFreq2 PARAM_DESCRIPTION replicates PARAM_DESCRIPTION, Default: 10000 filter PARAM_DESCRIPTION, Default: NULL","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateSNPindex_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"simulate snp index — simulateSNPindex_local","text":"OUTPUT_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/simulateSNPindex_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"simulate snp index — simulateSNPindex_local","text":"DETAILS","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tidy_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy data from gds file — tidy_metrics","title":"Tidy data from gds file — tidy_metrics","text":"Tidy data long format column sample, variant, metric name. internal use ","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tidy_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy data from gds file — tidy_metrics","text":"","code":"tidy_metrics(data_mat, values_cname, rnames, cnames)"},{"path":"https://cmatkhan.github.io/BSA/reference/tidy_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy data from gds file — tidy_metrics","text":"data_mat data matrix sample x variant format values_cname name metric -- eg RealDepth rnames vector name columns, eg sample.ids cnames vector name rows, eg variant_ids","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tidy_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy data from gds file — tidy_metrics","text":"tidy dataframe long format columns sample, variant, metric","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tile_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Tile Metrics Dataframe — tile_metrics","title":"Tile Metrics Dataframe — tile_metrics","text":"FUNCTION_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tile_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tile Metrics Dataframe — tile_metrics","text":"","code":"tile_metrics(   metrics_df,   genome_tile_df,   chr_seqlength,   cut_col = \"POS\",   left_inclusive = TRUE,   right_inclusive = FALSE )"},{"path":"https://cmatkhan.github.io/BSA/reference/tile_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tile Metrics Dataframe — tile_metrics","text":"metrics_df PARAM_DESCRIPTION genome_tile_df PARAM_DESCRIPTION chr_seqlength PARAM_DESCRIPTION cut_col PARAM_DESCRIPTION, Default: 'POS' left_inclusive PARAM_DESCRIPTION, Default: TRUE right_inclusive PARAM_DESCRIPTION, Default: FALSE","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tile_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tile Metrics Dataframe — tile_metrics","text":"OUTPUT_DESCRIPTION","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tile_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tile Metrics Dataframe — tile_metrics","text":"DETAILS","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/reference/tile_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tile Metrics Dataframe — tile_metrics","text":"","code":"if (FALSE) { if(interactive()){  #EXAMPLE1  } }"},{"path":"https://cmatkhan.github.io/BSA/reference/tricubeStat_local.html","id":null,"dir":"Reference","previous_headings":"","what":"calc tricube stat — tricubeStat_local","title":"calc tricube stat — tricubeStat_local","text":":ocal regression (wrapper locfit) predict tricube smoothed version statistic supplied SNP. works weighted average across neighboring SNPs accounts Linkage disequilibrium (LD) minizing noise attributed SNP calling errors. Values neighboring SNPs within window weighted physical distance focal SNP.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tricubeStat_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calc tricube stat — tricubeStat_local","text":"","code":"tricubeStat_local(POS, Stat, windowSize = 2e+06)"},{"path":"https://cmatkhan.github.io/BSA/reference/tricubeStat_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calc tricube stat — tricubeStat_local","text":"POS vector genomic positions SNP Stat vector values given statistic SNP windowSize window size (base pairs) bracketing SNP calculate statitics. Magwene et. al recommend window size ~25 cM, also recommend optionally trying several window sizes test peaks - undersmoothed. Default: 2e+06","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tricubeStat_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calc tricube stat — tricubeStat_local","text":"Returns vector weighted statistic caluculted tricube smoothing kernel","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tricubeStat_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"calc tricube stat — tricubeStat_local","text":"DETAILS","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/tricubeStat_local.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"calc tricube stat — tricubeStat_local","text":"example QTLSeqR: df_filt_4mb$Gprime <- tricubeStat(POS, Stat = GStat, WinSize = 4e6)","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/reference/vcf_to_qtlseqr_table.html","id":null,"dir":"Reference","previous_headings":"","what":"VCF to QTLseqR table — vcf_to_qtlseqr_table","title":"VCF to QTLseqR table — vcf_to_qtlseqr_table","text":"Process VCF, create gds file, return table long format. See return column list","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/vcf_to_qtlseqr_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VCF to QTLseqR table — vcf_to_qtlseqr_table","text":"","code":"vcf_to_qtlseqr_table(   vcf_path,   gds_outdir,   depth_thres = 5,   ref_freq_thres = 0.9,   parent_ref_sample = NULL,   parent_alt_sample = NULL,   parent_filter = FALSE,   single_allele_loci_only = TRUE,   overwrite = FALSE,   verbose = FALSE )"},{"path":"https://cmatkhan.github.io/BSA/reference/vcf_to_qtlseqr_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VCF to QTLseqR table — vcf_to_qtlseqr_table","text":"vcf_path Path VCF file, presumably one number samples gds_outdir directory write gds file depth_thres minimum required (filtered) depth consider calling genotype. Less genotype labelled lowDepth, Default: 5 ref_freq_thres minimum (greater equal ) required percentage genotype called Reference Alternative, Default: 0.9 parent_ref_sample name sample identifies 'reference' parent strain, eg cryptococcus KN99alpha. Default NULL parent_alt_sample name sample identifies 'alternate' parent strain, eg cryptococcus TDY1993 Default NULL parent_filter Boolean, default FALSE. Set TRUE retain loci parent_ref_strain labelled Reference parent_alt_strain labelled Alternate single_allele_loci_only Boolean, set TRUE exclude multi allelic loci. Set FALSE keep variants, Default: TRUE overwrite gds already exists, skip creating just open. Default FALSE verbose Boolean. Set true set SeqArray functions verbose. Default FALSE.","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/vcf_to_qtlseqr_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VCF to QTLseqR table — vcf_to_qtlseqr_table","text":"dataframe following columns:  CHR POS REF_Allele ALT1 QUAL Depth variant sample RealDepth Reference Alternative1 genotype Ref_percentage Alt1_percentage Filt_Genotype","code":""},{"path":"https://cmatkhan.github.io/BSA/reference/vcf_to_qtlseqr_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"VCF to QTLseqR table — vcf_to_qtlseqr_table","text":"function re-interpretation Daniel's script /scratch/mblab/daniel.agustinho/tools/VCF_tabler.sh. script parsed VCF files series awk commands. Critically, info line VCF expected following format: GT:DP:AD:RO:QR:AO:QA:GL. read script, see awk command extracted columns 1-9, CHROM  POS ID  REF ALT QUAL  FILTER  INFO  FORMAT loop, also extracts given sample column. column format given INFO column, GT:DP:AD:RO:QR:AO:QA:GL, stated . Real depth calculated replacing colons field separators extracting columns 13 15, correspond RO AO respectively. mimicked re-interpreted function.","code":""},{"path":[]},{"path":"https://cmatkhan.github.io/BSA/reference/vcf_to_qtlseqr_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VCF to QTLseqR table — vcf_to_qtlseqr_table","text":"","code":"if (FALSE) { if(interactive()){  #EXAMPLE1  } }"},{"path":"https://cmatkhan.github.io/BSA/news/index.html","id":"bsa-100","dir":"Changelog","previous_headings":"","what":"BSA 1.0.0","title":"BSA 1.0.0","text":"documentation point minimally helpful, much template removed README. serves first ‘official’ release, though updates least documentation shortly.","code":""},{"path":"https://cmatkhan.github.io/BSA/news/index.html","id":"bsa-000","dir":"Changelog","previous_headings":"","what":"BSA 0.0.0","title":"BSA 0.0.0","text":"NEW FEATURES Added NEWS.md file track changes package. SIGNIFICANT USER-VISIBLE CHANGES main changes function foo() parameter param. BUG FIXES bug fixes. See details http://bioconductor.org/developers/package-guidelines/#news.","code":""}]
